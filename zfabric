#!/usr/bin/env python3

"""zFabric client"""

import argparse
import base64
import datetime
import json
import os
import select
import signal
import sys
from typing import List, Dict, Optional, Any, Union
from http.server import HTTPServer, BaseHTTPRequestHandler
import shutil
import shlex
import threading

from dotenv import load_dotenv
import pyperclip
import requests

from tools.extract import yt
from tools.extract import web
from tools.extract import confluence
from tools.save import joplin as joplin_save
from server.helpers import load_file

ENV_PATH = "~/.config/zfabric/.env"
TIMEOUT = None

# ANSI Escape Codes
BOLD_START = "\033[1m"
BOLD_END = "\033[0m"


def validate_key_value(arg):
    """Simple test to check if key-value pair is readable"""
    if "=" not in arg:
        raise argparse.ArgumentTypeError(
            f"Argument '{arg}' is not in key=value format")
    return arg


def parse_variables(variables_to_parse):
    """Return a dict of variables"""
    return dict([v.split("=") for v in variables_to_parse])


def signal_handler(sig, frame):
    print()
    sys.exit(0)


def stdin_has_pipe():
    """Check if there is a pipe connected to stdin"""
    return not sys.stdin.isatty()


def stdin_has_data():
    """Test stdin for data
    Not used!
    """
    if not stdin_has_pipe():
        return False
    try:
        print("waiting for data")
        return select.select([sys.stdin], [], [], 0)[0] != []
    except ValueError:  # stdin might be closed
        return False


def get_yt_data(
    yt_url: str,
    transcripts: bool = True,
    metadata: bool = False,
    comments: bool = False,
):
    """Wrapper to external function to get data from YT"""
    options = type(
        "",
        (),
        {
            "duration": False,
            "transcript": transcripts,
            "comments": comments,
            "metadata": metadata,
            "transcript_as_list": False,
            "lang": "en",
        },
    )()
    ret = yt.main_function(yt_url, options, return_only=True)

    if ret:
        return ret

    raise ValueError("No data received from Youtube")


def get_web_data(web_url: str):
    """Wrapper to external function that scrapes a URL and returns text"""
    return web.WebExtractor().extract(web_url, "jina.ai")


def get_confluence_data(page_id: int, recursive: bool = False):
    """Wrapper to external function that downloads Confluence page data"""
    client = confluence.ConfluenceClient()
    contents = client.get_page_by_id(page_id, recursive=recursive)
    return "\n\n---------\n\n".join([content["body"]["view"]["value"] for content in contents])


def read_input(
    files: Optional[List[str]] = None,
    yt_url: Optional[str] = None,
    yt_options: Optional[Dict[str, bool]] = None,
    web_url: Optional[str] = None,
    attachments: List[str] = [],
    confluence_page_id: Optional[int] = None,
    recursive: bool = False,
) -> Dict[str, str]:
    """Read input from file/stdin or other sources"""
    input_data = {"input": ""}

    if files is not None and len(files) > 0:
        for file_meta in files:
            if ":" in file_meta:
                tag, path = file_meta.split(":", 1)
            else:
                tag = "file_input"
                path = file_meta
            with open(path, "r", encoding="utf-8") as f_desc:
                input_data[tag] = f_desc.read()

    if stdin_has_pipe():
        input_data["input"] = sys.stdin.read().rstrip()

    if yt_url:
        if yt_options is None:
            yt_options = {}
        yt_data = get_yt_data(yt_url, **yt_options)
        input_data["yt_input"] = json.dumps(yt_data)

    if web_url:
        web_data = get_web_data(web_url)
        input_data["web_input"] = json.dumps(web_data)

    if len(attachments) > 0:
        input_data["attachments"] = []
        for attachment in attachments:
            input_data["attachments"].append(
                base64.b64encode(
                    load_file(attachment, type="rb")).decode("ascii")
            )
    # if attachment:
    #    input_data["attachment"] = base64.b64encode(
    #        load_file(attachment, type="rb")
    #    ).decode("ascii")

    if confluence_page_id:
        input_data["confl_input"] = get_confluence_data(
            confluence_page_id, recursive=recursive)

    return input_data


def file_exists(file_path):
    """Custom argparse type to check if the file path is valid."""
    if not os.path.exists(file_path):
        raise argparse.ArgumentTypeError(f"File '{file_path}' does not exist.")
    if not os.path.isfile(file_path):
        raise argparse.ArgumentTypeError(f"'{file_path}' is not a file.")
    return file_path


def file_not_exists(file_path):
    """Custom argparse type to check if the file at path does not exist."""
    if os.path.exists(file_path):
        raise argparse.ArgumentTypeError(f"File '{file_path}' already exists.")
    return file_path


def set_options(parsed_args):
    """Set options in a JSON compatible format"""
    options = {}
    if parsed_args.num_ctx is not None:
        options["num_ctx"] = parsed_args.num_ctx
    if parsed_args.num_predict is not None:
        options["num_predict"] = parsed_args.num_predict
    if parsed_args.temperature is not None:
        options["temperature"] = parsed_args.temperature
    if parsed_args.topp is not None:
        options["topp"] = parsed_args.topp
    if parsed_args.frequencypenalty is not None:
        options["frequencypenalty"] = parsed_args.frequencypenalty
    if parsed_args.presencepenalty is not None:
        options["presencepenalty"] = parsed_args.presencepenalty
    return options


def send_query(
    generation_url: str,
    params: Optional[Dict] = None,
    post_data: Optional[Dict] = None,
    method: str = "GET",
):
    """Send query to generation endpoint"""
    if params is None:
        params = {}

    if post_data is not None and method == "GET":
        method = "POST"

    headers = {
        "Authorization": "bearer " + str(os.getenv("ZF_SERVER_TOKEN")),
        "Content-Type": "Application/json",
    }
    try:
        if method == "POST":
            query_response = requests.post(
                generation_url,
                headers=headers,
                json=post_data,
                stream=params["stream"],
                params=params,
                timeout=TIMEOUT,
            )
        elif method == "GET":
            query_response = requests.get(
                generation_url, headers=headers, params=params, timeout=TIMEOUT
            )
        elif method == "DELETE":
            query_response = requests.delete(
                generation_url, headers=headers, params=params, timeout=TIMEOUT
            )
        else:
            query_response = None
    except requests.exceptions.ConnectionError as ex:
        print(f"Connection to the server failed: {ex}")
        return

    return query_response


def print_usage(need_print: bool, response_json: Dict):
    """Print errors from HTTP responses"""
    if need_print and "usage" in response_json:
        print()
        for k, v in response_json["usage"].items():
            print(f"{k}: {v}")


def print_error(response_json):
    """Print error data from HTTP responses"""
    if "error" in response_json:
        print(f"Error: {response_json['error']}")


def print_warnings(response_json):
    """Print warning data from HTTP responses"""
    if "warnings" in response_json:
        for warn in response_json["warnings"]:
            print(f"Warning: {warn}")


def print_response(
    response,
    ofile: Optional[str] = None,
    ccopy: bool = False,
    joplin: bool = False,
    stream: bool = False,
    usage: bool = False,
):
    """Print (streamind) response to stdout and optionally:
    1. save to file
    2. copy to clipboard
    """

    if response is None:
        return

    if not response.ok:
        print_error(response.json())
        return

    response_text = ""
    if stream:
        response_json = {}
        for chunk in response.iter_lines():
            response_json = json.loads(chunk)
            print_warnings(response_json)
            if "response" in response_json:
                response_text += response_json["response"]
                print(response_json["response"], end="", flush=True)
            print_error(response_json)
        print("\n", end="", flush=True)
        print_usage(usage, response_json)
    else:
        response_json = response.json()
        if "response" in response_json:
            response_text = response_json["response"]
            if len(response_text):
                print(response_text)
        print_usage(usage, response_json)
        print_error(response_json)
        print_warnings(response_json)

    write_alternative_outputs(
        response_text, ccopy=ccopy, ofile=ofile, joplin=joplin)

    if "session" in response_json:
        return response_json["session"]


def write_alternative_outputs(
    text: str,
    ccopy: bool = False,
    ofile: Optional[str] = None,
    joplin: Optional[bool] = False,
    force: bool = False,
):
    """Write output using alternative (non-stdout) outputs"""

    if not len(text) and not force:
        return

    if ofile is not None:
        with open(ofile, "w", encoding="utf-8") as f:
            f.write(text)

    if ccopy is not None:
        pyperclip.copy(text)

    if joplin:
        parent_id = os.getenv("JOPLIN_DEFAULT_FOLDER")
        title = datetime.datetime.now().strftime("Imported - %y-%m-%d_%H-%M-%S")
        joplin_save.create_note(parent_id, title, text)


def print_str(output: str, ccopy: bool = False, ofile: Optional[str] = None, joplin: bool = False):
    """Print string to stdout and optionally:
    1. save to file
    2. copy to clipboard
    """

    if len(output):
        print(output)
    write_alternative_outputs(output, ccopy=ccopy, ofile=ofile, joplin=joplin)


def print_list(
    response_list: List[str], ccopy: bool = False, ofile: Optional[str] = None, joplin: bool = False
):
    """Print list of strings using print_str"""

    output = ""
    for elem in response_list:
        output += elem
        if elem != response_list[-1]:
            output += "\n"
    print_str(output, ccopy=ccopy, ofile=ofile, joplin=joplin)


def print_chat(
    response_list: List[Dict[str, Any]],
    ccopy: bool = False,
    ofile: Optional[str] = None,
    joplin: bool = False,
):
    """Print list of messages using print_str"""

    output = ""
    for msg in response_list:
        role = msg["data"]["role"]
        image_content = False
        if not isinstance(msg["data"]["content"], list):
            content = msg["data"]["content"].strip()
        else:
            content = ""
            for m in msg["data"]["content"]:
                if m["type"] == "text":
                    content += m["text"]
                elif m["type"] == "image_url":
                    image_content = True
        if role == "assistant":
            metadata = msg["data"]["response_metadata"]
            # timestamp = metadata["timestamp"]
            model = metadata["model"]
            output += f"{BOLD_START}{role.title()} ({model}){BOLD_END}: {content}"
        else:
            output += (
                f"{BOLD_START}{role.title()}"
                + f"{BOLD_END}{' (image_attachment)' if image_content else ''}: {content}"
            )
        if msg != response_list[-1]:
            output += "\n"
    print_str(output, ccopy=ccopy, ofile=ofile, joplin=joplin)


def list_sessions(
    session: str, ccopy: bool = False, ofile: Optional[str] = None, joplin: bool = False
):
    """Print a session's history"""
    url = base_url + "/session/" + session

    query_params = {
        "session": session,
    }
    resp = send_query(url, query_params)
    if resp is None:
        return
    print_error(resp)
    resp_json = resp.json()
    if resp.ok and "response" in resp_json:
        print_chat(resp_json["response"], ofile=ofile,
                   ccopy=ccopy, joplin=joplin)


def list_objects(
    object_name: str, ccopy: bool = False, ofile: Optional[str] = None, joplin: bool = False
):
    """Print objects defined by -l cli argument"""
    resp = send_query(base_url + "/" + object_name)
    if resp is None:
        return
    print_error(resp)
    resp_json = resp.json()
    if resp.ok and "response" in resp_json:
        print_list(resp_json["response"], ccopy=ccopy,
                   ofile=ofile, joplin=joplin)


def read_cli_input():
    if not sys.stdin.isatty():
        # reopen tty as we lost that with sys.stdin.read()
        sys.stdin = open("/dev/tty", "r", encoding="utf-8")
    try:
        return input("> ")
    except EOFError:
        # catch ctrl+d
        print()
        sys.exit(0)


def query_server(
    qry_str: str,
    args: argparse.Namespace,
    post_data: Dict[str, str],
    qparams: Dict[str, Union[str, int, bool]] = {},  # used to overrride args
    method: str = "GET",
):
    query_params = {
        "profile": qparams.get("profile", args.profile),
        "variables": qparams.get("variable", args.variable),
        "model": qparams.get("model", args.model),
        "options": qparams.get("options", json.dumps(set_options(args))),
        "keep_alive": qparams.get("keep_alive", args.keepalive),
        "stream": qparams.get("stream", not args.no_stream),
        "session": qparams.get("session", args.session),
        "contexts": ",".join(qparams.get("context", args.context)),
        "no_think": qparams.get("no_think", args.no_think),
    }
    if not len(post_data) > 0 and not args.delete:
        post_data["input"] = read_cli_input()

    while True:
        resp = send_query(qry_str, params=query_params,
                          post_data=post_data, method=method)

        session_id = print_response(
            resp,
            ofile=args.ofile,
            ccopy=args.copy,
            joplin=args.joplin,
            stream=bool(qparams.get("stream", not args.no_stream)),
            usage=args.usage,
        )
        # Exit, unless:
        # 1. chat is True
        # 2. delete command
        # 3. session_id is None (skip saving session, so no state on server side)
        if not args.chat or args.delete or session_id is None:
            return

        # set session to the one received from server
        query_params["session"] = session_id

        post_data = {}
        post_data["input"] = read_cli_input()


def get_yt_options(args: argparse.Namespace):
    """Return a dict with options for yt.py
    Enabled transcripts if everything else is off
    """

    # enable transcripts and metadata if everything is off
    transcripts = args.yt_transcripts
    metadata = args.yt_metadata
    if not (args.yt_metadata or args.yt_comments or args.yt_transcripts):
        transcripts = True
        # metadata = True

    return {
        "metadata": metadata,
        "comments": args.yt_comments,
        "transcripts": transcripts,
    }


class CustomAction(argparse.Action):
    """Custom action for ArgParse:
    1. If the flag was specified without a value, set the default value
    1. If the flag was not specified at all, set to None
    1. If the flag was specified with a value, use that value
    """

    def __call__(self, cparser, namespace, values, option_string=None):
        if self.default is not None and values is None:
            # If the flag was specified without a value, set the default value
            setattr(namespace, self.dest, self.default)
        elif values is None:
            # If the flag was not specified at all, set to None
            setattr(namespace, self.dest, None)
        else:
            # If the flag was specified with a value, use that value
            setattr(namespace, self.dest, values)


class CommandHandler(BaseHTTPRequestHandler):
    def log_message(self, format, *args):
        # Suppress default logging
        pass

    def do_POST(self):
        # Acquire the lock to ensure only one request is processed at a time
        with request_lock:
            # Check authentication
            auth_token = self.server.auth_token
            if auth_token:
                auth_header = self.headers.get("Authorization")
                if not auth_header or not auth_header.startswith("Bearer "):
                    self.send_error(
                        401, "Missing or invalid Authorization header")
                    return
                provided_token = auth_header.split(" ")[1]
                if provided_token != auth_token:
                    self.send_error(401, "Invalid authentication token")
                    return

            # Get command from request body
            content_length = int(self.headers.get("Content-Length", 0))
            if content_length == 0:
                self.send_error(400, "Missing command in request body")
                return

            command_line = self.rfile.read(content_length).decode("utf-8")
            print("#" * shutil.get_terminal_size().columns)
            print("Command received: " + command_line)

            self.send_response(200)
            self.end_headers()
            self.wfile.flush()

            threading.Thread(target=self._execute_command_async,
                             args=(command_line,)).start()

    def _execute_command_async(self, command_line):
        """Execute the command in a separate thread to avoid blocking"""
        cli_args = parse_cli_args(command_line)
        print("-" * shutil.get_terminal_size().columns)
        execute_command(cli_args)


def execute_command(cli_args):
    """Execute a command based on parsed cli_args"""

    if cli_args.listen:
        global request_lock
        request_lock = threading.Lock()
        start_http_listener(cli_args.auth_token)
        sys.exit(0)

    data = read_input(
        cli_args.ifile,
        cli_args.yt,
        get_yt_options(cli_args),
        cli_args.url,
        cli_args.attachment,
        cli_args.cnfl,
        cli_args.cnfl_recursive,
    )

    if cli_args.list:
        if cli_args.session:
            list_sessions(
                cli_args.session,
                ccopy=cli_args.copy,
                ofile=cli_args.ofile,
                joplin=cli_args.joplin,
            )
        else:
            list_objects(
                cli_args.list, ccopy=cli_args.copy, ofile=cli_args.ofile, joplin=cli_args.joplin
            )
    elif cli_args.delete and cli_args.session:
        query_server(
            base_url + "/session/" + cli_args.session,
            cli_args,
            data,
            qparams={"stream": False},
            method="DELETE",
        )
    elif cli_args.tokens:
        query_server(base_url + "/tokens", cli_args,
                     data, qparams={"stream": False})
    elif cli_args.pattern:
        query_server(base_url + "/patterns/" +
                     cli_args.pattern, cli_args, data)
    elif (len(data) > 0 or cli_args.chat) and cli_args.session:
        query_server(base_url + "/session", cli_args, data)
    else:
        output = ""
        for k, v in data.items():
            if len(v):
                output += "### " + k + "\n" + str(v) + "\n"
        print_str(output, ccopy=cli_args.copy,
                  ofile=cli_args.ofile, joplin=cli_args.joplin)


def start_http_listener(auth_token=None):
    """Start HTTP listener on localhost:12345"""
    server = HTTPServer(("localhost", 12345), CommandHandler)
    server.auth_token = auth_token
    print("HTTP listener started on http://localhost:12345")
    # Disable threading to ensure requests are processed one at a time
    server.request_queue_size = 1
    if auth_token:
        print(f"Authentication token: {auth_token}")
    print("Press Ctrl+C to stop")

    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nShutting down...")
        server.shutdown()


def parse_cli_args(command_args=None):
    command = shlex.split(command_args) if command_args else None

    parser = argparse.ArgumentParser(description="zFabric client application")
    group = parser.add_mutually_exclusive_group(required=False)

    parser.add_argument(
        "--listen",
        default=False,
        action="store_true",
        help="Start HTTP listener mode on port 12345",
    )
    parser.add_argument(
        "--auth-token",
        type=str,
        default=None,
        help="Authentication token for HTTP listener",
    )

    group.add_argument(
        "-l",
        "--list",
        type=str,
        action=CustomAction,
        nargs="?",
        choices=["profiles", "patterns", "sessions", "contexts"],
        const="patterns",
        help="List patterns/profiles/sessions/contexts",
    )
    group.add_argument(
        "--delete", default=False, action="store_true", help="Used to delete a session"
    )
    group.add_argument("-p", "--pattern", default=None, help="Pattern to use")
    group.add_argument(
        "--tokens",
        default=False,
        action="store_true",
        help="Count tokens in input (using OpenAI's tiktoken), and exit",
    )

    parser.add_argument(
        "-i",
        "--ifile",
        type=file_exists,
        default=[],
        action="append",
        help="Input file path(s) in [<template_tag>:]<file_path> format",
    )
    parser.add_argument(
        "-o", "--ofile", type=file_not_exists, default=None, help="Output file path"
    )
    parser.add_argument(
        "-j", "--joplin", default=False, action="store_true", help="Send output to Joplin"
    )
    parser.add_argument(
        "-c",
        "--copy",
        default=False,
        action="store_true",
        help="Copy output to clipboard",
    )
    parser.add_argument(
        "--chat",
        default=False,
        action="store_true",
        help="Start chat session",
    )
    parser.add_argument(
        "-a",
        "--attachment",
        type=file_exists,
        action="append",
        default=[],
        help="Path of file attachment (for binary files, like images)",
    )
    parser.add_argument(
        "--yt",
        type=str,
        default=None,
        help="YT URL to download transcript and use it as {{input}} or {{yt_input}}",
    )
    parser.add_argument(
        "--yt-transcripts",
        default=False,
        action="store_true",
        help="Download video transcript (default)",
    )
    parser.add_argument(
        "--yt-metadata",
        default=False,
        action="store_true",
        help="Download video metadata",
    )
    parser.add_argument(
        "--yt-comments",
        default=False,
        action="store_true",
        help="Download video comments",
    )
    parser.add_argument(
        "-u",
        "--url",
        type=str,
        default=None,
        help="Input URL to be scraped for text input",
    )
    parser.add_argument(
        "--cnfl",
        type=str,
        default=None,
        help="Input a Confluence page ID and get page data",
    )
    parser.add_argument(
        "--cnfl-recursive",
        default=False,
        action="store_true",
        help="Retrieve Confluence child pages recursively (limited to 10 pages)",
    )
    parser.add_argument(
        "-v",
        "--variable",
        action="append",
        type=validate_key_value,
        default=[],
        help="Input variables to be replaced in patterns",
    )
    parser.add_argument(
        "--context",
        action="append",
        type=str,
        default=[],
        help="Context files to attach to the query in [<template_tag>:]<context_name> format",
    )
    parser.add_argument(
        "--usage",
        action="store_true",
        default=False,
        help="Print token usage if streaming (currently the Azure API is buggy)",
    )

    parser.add_argument(
        "--num_ctx",
        default=None,
        type=int,
        help="Ollama variable to set model context size",
    )
    parser.add_argument(
        "-n",
        "--num_predict",
        default=None,
        type=int,
        help="Maximum number of tokens to predict",
    )
    parser.add_argument(
        "-t",
        "--temperature",
        default=None,
        type=float,
        help="Set temperature for the model. Increasing the temperature will "
        "make the model answer more creatively.",
    )
    parser.add_argument(
        "-T",
        "--topp",
        default=None,
        type=float,
        help="Set top-P value. Output tokens are selected from the most to "
        "least probable until the sum of their probabilities equals to top-P.",
    )
    parser.add_argument(
        "-F",
        "--frequencypenalty",
        default=None,
        type=float,
        help="Positive values penalize new tokens based on their existing "
        "frequency in the text so far, decreasing the model's likelihood "
        "to repeat the same line verbatim.",
    )
    parser.add_argument(
        "-P",
        "--presencepenalty",
        default=None,
        type=float,
        help="Positive values penalize new tokens based on whether they "
        "appear in the text so far, increasing the model's likelihood to talk "
        "about new topics.",
    )
    parser.add_argument(
        "--keepalive",
        default=None,
        type=str,
        help="How long to keep loaded model in memory (Ollama only), for example '5m' or '1h' or '3600' (seconds)",
    )
    parser.add_argument(
        "--no-think",
        default=False,
        action="store_true",
        help="Prefix prompt with no_think, this way disable reasoning in Qwen3 models",
    )

    parser.add_argument(
        "-s",
        "--session",
        default=None,
        type=str,
        help="Session name to insert/query, use 'skip' to skip saving session",
    )

    parser.add_argument("-r", "--profile",
                        help="Profile to use (defined in server config.json)")
    parser.add_argument(
        "--no-stream",
        default=False,
        action="store_true",
        help="Disable streaming response (default: False)",
    )
    parser.add_argument("-m", "--model", default=None, help="Model to query")

    return parser.parse_args(command)


if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    load_dotenv(os.path.expanduser(ENV_PATH))

    base_url = os.getenv("BASE_URL", default="http://localhost:13337")

    cli_args = parse_cli_args()
    # variables = parse_variables(cli_args.variable)
    execute_command(cli_args)
